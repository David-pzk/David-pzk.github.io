<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>David</title>
  
  <subtitle>Love the sunshine ,Enjoy the rainy day!</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://david-pzk.github.io/"/>
  <updated>2018-11-24T12:51:21.741Z</updated>
  <id>https://david-pzk.github.io/</id>
  
  <author>
    <name>David-pzk</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>自然语言处理——情感分析模型</title>
    <link href="https://david-pzk.github.io/2018/11/24/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E2%80%94%E2%80%94%E6%83%85%E6%84%9F%E5%88%86%E6%9E%90%E6%A8%A1%E5%9E%8B/"/>
    <id>https://david-pzk.github.io/2018/11/24/自然语言处理——情感分析模型/</id>
    <published>2018-11-23T16:00:00.000Z</published>
    <updated>2018-11-24T12:51:21.741Z</updated>
    
    <content type="html"><![CDATA[<h1 id="自然语言处理之情感分析模型-——————SOSML模型"><a href="#自然语言处理之情感分析模型-——————SOSML模型" class="headerlink" title="自然语言处理之情感分析模型 ——————SOSML模型"></a>自然语言处理之情感分析模型 ——————SOSML模型</h1><p>“从这篇文章开始，便是记录我在自然语言处理情感分析模型的学习之路，以期望能实现一个完整的情感分析模型”                                         </p><div align="right"> ———前记</div><p>&#160; &#160; &#160; &#160;Asad Abdi等人在情感分析模型中实现了一种基于机器学习的多文档情感概括分析模型，该模型结合了情感知识、深度学习系统、统计和语义知识，简称为SOSML模型。    </p><a id="more"></a><h2 id="相关知识概括"><a href="#相关知识概括" class="headerlink" title="相关知识概括"></a>相关知识概括</h2><p>&#160; &#160; &#160; &#160;在介绍SOSML模型前，我将首先根据该文介绍一下情感分析的相关寄出知识点，在后面的文章中，我也不再对该部分进行过多的赘述。</p><h3 id="情感分析（Sentiment-analysis）"><a href="#情感分析（Sentiment-analysis）" class="headerlink" title="情感分析（Sentiment analysis）"></a>情感分析（Sentiment analysis）</h3><p>&#160; &#160; &#160; &#160;SA是自然语言处理(NLP)领域中一个热门研究方向，它可以通过研究人们的情感为企业和政府所作出的决策产生一些影响。情感分析可分为句式分析、文本分析和方面分析，其中句式和文本分析仅是分析句子或文本的积极与消极的极性。而方面分析则可以检测人们喜欢与不喜欢的对象和具体的喜欢程度。  </p><p>&#160; &#160; &#160; &#160;情感分析的方式可以分为3种途径：(1)、基于机器学习，(2)、基于词典，(3)、混合方式。而常用的机器方法为支持向量机(SVM)、朴素贝叶斯(NB)、随机梯度向量(SGD)等。  </p><h3 id="文本摘要-Summarization"><a href="#文本摘要-Summarization" class="headerlink" title="文本摘要(Summarization)"></a>文本摘要(Summarization)</h3><p>&#160; &#160; &#160; &#160;文本摘要是概括文本情感特种的重要内容，文本概括可分为一般摘要和面向查询的摘要，一般摘要主要是对文本文意的概括，而面向查询的摘要则是根据用户的查询所进行的。其中对文本文意的概括还可以分为抽取和抽象两种方式，抽取是从文本种找寻代表语句，而抽象则是使用新的词与句来对文本进行概括。文本分析一般分为三个步骤：(1)、解释——处理输入文本，挑选显著特征，(2)、转化——将上部所得结果转化为一个摘要表示，(3)、生成——将摘要表示生成合适得摘要。由于大量文本充斥着人们得主观意见，因此生成简明信息的文本摘要和总结大量评论者和评论的情感摘要开始结合。</p><h2 id="SOSML系统架构"><a href="#SOSML系统架构" class="headerlink" title="SOSML系统架构"></a>SOSML系统架构</h2><p>&#160; &#160; &#160; &#160;SOSML主要基于句式分析，大致分为四个步骤：(1)预处理（Pre-processing）——用基础的自然语言方法处理评论文本(2)特征抽取（Feature extraction）——抽取一组特征改善分类质量(3)分类（Classification）——对评论文本进行分类(4)摘要生成步骤（The summary generation）检查冗余信息，生成最终摘要。</p><h3 id="预处理"><a href="#预处理" class="headerlink" title="预处理"></a>预处理</h3><p>&#160; &#160; &#160; &#160;预处理是为了对数据集采用基础语义功能使得数据更适合于文本挖掘技术。该步骤在SOSML系统中主要有一下功能：句式划分(sentence splitting)、词干提取(stemming)、停用词删除(stop-word deletion)和词性标注(part-of-speech(pos) tagging)。</p><h4 id="特征抽取"><a href="#特征抽取" class="headerlink" title="特征抽取"></a>特征抽取</h4><p>&#160; &#160; &#160; &#160;特征是一种能够抓取数据模型的文本属性。特征概括主要是为了抽取一系列特征以改善总体的文本分类质量。系统中特征提取的步骤如下：  </p><p><strong><em>（一）情感知识</em></strong><br>&#160; &#160; &#160; &#160;<em>情感词典特征(Sentiment lexicon feature)</em>——情感词典是一组用于表达积极或消极情感的词语，在本模型中，我们使用HCLr来抽取以出现频率为其值得积极或消极词汇。</p><p>&#160; &#160; &#160; &#160;<em>否定特征(Negation features)</em>——否定词汇为那些影响句式极性得词汇，如：”I do not like this chair”，其中得not改变了句式的情感极性。系统中记录否定词的数量。</p><p>&#160; &#160; &#160; &#160;<em>句式类型(Sentence types)</em>——主观和客观句，条件和疑问句。</p><p>&#160; &#160; &#160; &#160;<em>标点特征(Punctuations feature)</em>——系统中记录“！“与”？“的数量。</p><p>&#160; &#160; &#160; &#160;<em>POS feature</em>——系统中还要考虑每个单词的词性，记各词性的数量。  </p><p>&#160; &#160; &#160; &#160;<em>情感分数特征(Sentiment score feature)</em>——通过基于情感词典获得的分数也作为参考的分数。  </p><p><strong><em>（二）统计和语言知识</em></strong><br>&#160; &#160; &#160; &#160;通过统计和语言知识准备一下特征：句子所在位置、标题词、关键词、线索词和句式将的相似度。  </p><p><strong><em>（三）词嵌入模型</em></strong><br>&#160; &#160; &#160; &#160;为了将自然语言处理功能转换为机器学习算法，文本必须首先被转换为合适的向量。在该系统中使用word2vec技术来进行特征的转换。Word2vec是一种基于机器学习的词向量提取技术。它尝试了解词的含义以及词间的语义关系，也就是通过映射词向量进入另一个向量空间，语义相似的词将会有相似的代表向量并且这些词向量具有相似的意思。Word2vec基于Skip-gram和continuous bag-of-words(CBOW) 词向量计算模型。Skip-gram通过一个单词来预测全文，CBOW则是通过上下文来预测单词。<br>&#160; &#160; &#160; &#160;取词向量的过程主要是基于Skip-gram模型，通过对神经网络的不断优化来取出输入层到隐藏层的转换向量，该向量则为词向量，值得注意的是该过程的目的并不是将训练好的模型用来预测词向量概率，而是为了取出隐藏层的转换向量，该向量则为对应的词向量，具体内容我将会再后面的章节用代码实现，读者可参考该链接：<a href="https://blog.csdn.net/rlnlo2pnefx9c/article/details/78747970" target="_blank" rel="noopener">https://blog.csdn.net/rlnlo2pnefx9c/article/details/78747970</a>。<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/1.jpg" alt=""><br>该公式为Skip-learn的概率显示公式，旨在最大化平均对数向量。</p><p>&#160; &#160; &#160; &#160;SOSML系统主首先将句式中的单词通过word2vec转换为适当的词向量，然后将不同的单词串联起来形成句向量，同时结合（一）（二）点得到的各特征，组成混合向量以适用于分类算法。  </p><h4 id="特征选择"><a href="#特征选择" class="headerlink" title="特征选择"></a>特征选择</h4><p>&#160; &#160; &#160; &#160;特征选择是为了选择一组对分类器重要的特征集，也就是移除对于分类器而言多余的特征集。该过程可以增加分类的准确度和改善分类器的运行时间或者减少特征空间的大小和该少分类的质量。</p><p>&#160; &#160; &#160; &#160;SOSML通过应用统计技术（如：information gain,Gain Ration,Relief-F,Symmetrical Uncertainty）来筛选出关键的特征。</p><p>&#160; &#160; &#160; &#160;<strong><em>Relief-F</em></strong>——该算法随机选择一个样本Xi,然后随机选择两个与之最近的邻近样本，一个与Xi属于同一类，另一个与之属于不同类。可参考<a href="https://blog.csdn.net/littlely_ll/article/details/71614826" target="_blank" rel="noopener">https://blog.csdn.net/littlely_ll/article/details/71614826</a><br>具体算法如下图所示：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/2.png" alt=""><br>&#160; &#160; &#160; &#160;<strong><em>Information gain(IG)</em></strong>——信息增益是用来选择决策树中分类特征。主要目标有：(1)选择有大量值得特征(2)决定特征得排序(3)决定有益于分类方法得特征。<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/3.png" alt=""><br>详细可参考：<a href="https://blog.csdn.net/qq_40587575/article/details/80219080" target="_blank" rel="noopener">https://blog.csdn.net/qq_40587575/article/details/80219080</a>  </p><p>&#160; &#160; &#160; &#160;<strong><em>Gain Ratio(GR)</em></strong>——GR为一种基于IG的特征选择算法，该值有标准化后的某特征的IG值评估得到。较高的GR值表明该特征适用于分类算法：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/4.png" alt=""></p><p>&#160; &#160; &#160; &#160;<strong><em>Symmetrical Uncertainty（SU）</em></strong>——SU算法使用称为对称不确定性的信息理论度量，因此SU（x，y）与SU（y，x）的SU（x，y）相同，因此它减少了所需的比较次数，其中x和y是两个特征。 设IG（x | y）为特征x的信息增益，H（x）为特征x的熵，H（y）为特征y的熵。使用以下等式计算SU：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/5.png" alt=""></p><p>&#160; &#160; &#160; &#160;经过特征抽取和特征选择，我们已经准备好适用于分类的文本或句式向量。</p><h3 id="分类算法"><a href="#分类算法" class="headerlink" title="分类算法"></a>分类算法</h3><p>&#160; &#160; &#160; &#160;SOSML系统中主要应用传统的机器学习算法，传统的机器学习算法一般为监督算法，将训练数据用于对模型的训练，再将训练模型用于未知的数据分类。</p><p>&#160; &#160; &#160; &#160;<strong><em>Support Vector Machine(SVM)</em></strong>——支持向量机为目前较为火爆的机器学习算法，该算法用于找到分割数据的“最大分类超平面”，<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/6.png" alt=""></p><p>w为超平面的法向量，b为超平面的偏置向量。通过将一式最小化即可找到划分数据集的最优分割平面。</p><p>&#160; &#160; &#160; &#160;<strong><em>Decision Tree(DT)</em></strong>——决策树算法使用属性结构对数据进行分类，决策树从单个节点开始，每个节点分支为可能的结果，叶节点为类标签，分支表示特征的连接，非叶子节点则为特征的分类条件。<br>&#160; &#160; &#160; &#160;<em>Navi Bays(NB)</em>——贝叶斯算法是基于概率的算法，估计每一个数值属于某个类别的准确概率。贝叶斯假设每一个特征都是互相独立的，一个样本c属于某个类别x的概率可由一下公式计算得到：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/7.png" alt=""></p><p>&#160; &#160; &#160; &#160;<strong><em>Logistic Regression (LR)</em></strong>——洛吉斯蒂克回归以一种基于一个特征集的统计方法得到数据的类别。它旨在找到一种模式用来描述标签结果和特征之间的关系：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/8.png" alt=""></p><p>&#160; &#160; &#160; &#160;在该系统中，作者使用了多种机器学习算法来进行数据的分类处理，其他还包括Random Frost(RF),K-Nearest Neighbour(KNN),Artifical Neural Network(ANN)算法，和之前的介绍的算法相同，这些算法都属于基础算法，在此不再详述，读者可自行百度。  </p><h3 id="情感得分"><a href="#情感得分" class="headerlink" title="情感得分"></a>情感得分</h3><p>&#160; &#160; &#160; &#160;在数据预处理步骤中，我们需要应用high-coverage lexical resourde(HCLr)来实现对单词情感得分的计算，由于每个词典都有其局限性，该系统集合了多个词典，提高了词典的覆盖程度：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/9.png" alt=""></p><p>&#160; &#160; &#160; &#160;在该系统中作者应用了Semantic Sentiment Approach(SSA)来实现对单词情感得分的计算：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/10.png" alt=""><br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/11.png" alt=""></p><p>&#160; &#160; &#160; &#160;系统还考虑了单词的上下文影响，也就是一个单词的极性可能会根据前后语句发生极性的逆转，如：The bed is not well,well 的极性就因为not的存在发生了逆转。常用的否定词如下：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/12.png" alt=""></p><p>&#160; &#160; &#160; &#160;系统还在句式分析上考虑罢了主客观语句、条件和疑问句、转折句式等。<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/13.png" alt=""></p><h3 id="统计和语言知识"><a href="#统计和语言知识" class="headerlink" title="统计和语言知识"></a>统计和语言知识</h3><p>&#160; &#160; &#160; &#160;文本总结的目标在于选择文档中最有意义的句子，所以确定这些特征有助于确认这个句子和改善总结的质量。在SOSML系统中，综合考虑了关键词、标题、句式位置、暗示词和句式相似性。<br>&#160; &#160; &#160; &#160;<strong><em>Key-word method</em></strong>——一个句子含有更多的关键词，可以说明这个句子有更高的代表性，采用如下公式计算：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/14.png" alt=""></p><p>TFi为关键词的频率，ND为文档的总数量，DFi为包含该关键词的文档数量。在SOSML系统中如果一个聚在含有一个关键词，则K(Si)=1;否则K(si)=0;  </p><p>&#160; &#160; &#160; &#160;<strong><em>Sentence Position methond</em></strong>——在一段文字中，有代表性的句子往往出现在段落的开头和段落的结尾，我们使用如下的公式来计算句子所在位置的分数：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/15.png" alt=""></p><p>N为句子的总数量，1&lt;i&lt;N  </p><p>&#160; &#160; &#160; &#160;<strong><em>Title method</em></strong>——出现在标题中的短语往往包含文本准确的含义，在SOSML系统中，如果一个句子含有一个标题词，则T(S)=1,否则T(S)=0。  </p><p>&#160; &#160; &#160; &#160;<strong><em>Cue method</em></strong>——线索短语往往能暗示后面句子的含义，所以系统中含有线索词的句子C(S )=1,否则C(S)=0。  </p><p>&#160; &#160; &#160; &#160;<strong><em>Sentence-to-sentences similarity based on the Vector Space Model(VSM):SSVSM</em></strong><br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/16.png" alt=""></p><p>&#160; &#160; &#160; &#160;<strong><em>Content Word Expansion(CWE)</em></strong>——是一种基于情感词相似性的方法，两个单词的语义相似度由以下步骤组成：    </p><p>&#160; &#160; &#160; &#160;<strong><em>Dice measure</em></strong>:<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/17.png" alt=""></p><p>Syns(w)是单词w基于wordnet的单词集。<br>&#160; &#160; &#160; &#160;<strong><em>Semantic Similarity Measurement(SSM)</em></strong>——该方法用来衡量两个语句的相似度，用一下的方式来表达：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/17.png" alt=""></p><p>&#160; &#160; &#160; &#160;<strong><em>Graph-based</em></strong>——在SOSML系统中，最后使用了每个句子再全文中的相似度来表现该句：<br><img src="http://pin4m4ioe.bkt.clouddn.com/%E8%87%AA%E7%84%B6%E8%AF%AD%E8%A8%80%E5%A4%84%E7%90%86%E6%A8%A1%E5%9E%8B/19.png" alt=""></p><p>T表示所有句子，sim(si,d)表示选定句Si与其他所有句子的相似度 。  </p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>&#160; &#160; &#160; &#160;高质量的文本摘要不仅必须是信息性的，还应该是简洁的（非冗余的）。必须删除冗余以避免重复信息。为此，该方法执行以下任务。设B 1 =∅表示空集，B 2 = {S i | i = 1,2 ……，N}表示每个句子的总相似度得分。 B 2的句子按其得分按降序排列。在第一步中，顶部句子从B 2移动到B 1。在第二步中，从B 2中选择下一个顶部句子，然后，在将当前句子添加到B 1之前，将检查该句子以确保它与上面的B 1的每个句子没有任何相似性度量。相似性阈值（ST）。如果是，则将句子添加到B 1中。否则，该句子将被删除。将重复这些步骤，直到满足最终摘要中的句子数。最后，集合B 1被视为最终摘要。为了估计ST的值，我们使用梯度搜索策略。我们实施了一组不同ST的实验，范围从0.1到0.9，以观察性能的变化。</p>]]></content>
    
    <summary type="html">
    
      &lt;h1 id=&quot;自然语言处理之情感分析模型-——————SOSML模型&quot;&gt;&lt;a href=&quot;#自然语言处理之情感分析模型-——————SOSML模型&quot; class=&quot;headerlink&quot; title=&quot;自然语言处理之情感分析模型 ——————SOSML模型&quot;&gt;&lt;/a&gt;自然语言处理之情感分析模型 ——————SOSML模型&lt;/h1&gt;&lt;p&gt;“从这篇文章开始，便是记录我在自然语言处理情感分析模型的学习之路，以期望能实现一个完整的情感分析模型”                                         &lt;/p&gt;
&lt;div align=&quot;right&quot;&gt; ———前记&lt;/div&gt;

&lt;p&gt;&amp;#160; &amp;#160; &amp;#160; &amp;#160;Asad Abdi等人在情感分析模型中实现了一种基于机器学习的多文档情感概括分析模型，该模型结合了情感知识、深度学习系统、统计和语义知识，简称为SOSML模型。    &lt;/p&gt;
    
    </summary>
    
      <category term="NLP" scheme="https://david-pzk.github.io/categories/NLP/"/>
    
    
      <category term="Hexo" scheme="https://david-pzk.github.io/tags/Hexo/"/>
    
      <category term="Markdown" scheme="https://david-pzk.github.io/tags/Markdown/"/>
    
      <category term="machinelearning" scheme="https://david-pzk.github.io/tags/machinelearning/"/>
    
      <category term="NLP" scheme="https://david-pzk.github.io/tags/NLP/"/>
    
      <category term="Sentiment Analysis" scheme="https://david-pzk.github.io/tags/Sentiment-Analysis/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://david-pzk.github.io/2018/10/14/hello-world/"/>
    <id>https://david-pzk.github.io/2018/10/14/hello-world/</id>
    <published>2018-10-14T02:25:31.300Z</published>
    <updated>2018-10-15T02:44:01.654Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.<br><a id="more"></a></p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;br&gt;
    
    </summary>
    
    
  </entry>
  
  <entry>
    <title>Hexo</title>
    <link href="https://david-pzk.github.io/2018/10/05/markdown/"/>
    <id>https://david-pzk.github.io/2018/10/05/markdown/</id>
    <published>2018-10-04T16:00:00.000Z</published>
    <updated>2018-11-16T05:45:06.365Z</updated>
    
    <content type="html"><![CDATA[<p>这是我所写的第一的hexo博客，这是一篇测试博客，我希望的我的机器学习之路可以再次上升到一个新的台阶。<br><a id="more"></a><br>本期我将熟悉logistic回归算法、随机梯度下降、随机森林以及k-means算法的相关实现，主要将以实验的方式实现其中的相关内容。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是我所写的第一的hexo博客，这是一篇测试博客，我希望的我的机器学习之路可以再次上升到一个新的台阶。&lt;br&gt;
    
    </summary>
    
      <category term="Markdown" scheme="https://david-pzk.github.io/categories/Markdown/"/>
    
    
      <category term="Hexo" scheme="https://david-pzk.github.io/tags/Hexo/"/>
    
      <category term="Markdown" scheme="https://david-pzk.github.io/tags/Markdown/"/>
    
  </entry>
  
</feed>
